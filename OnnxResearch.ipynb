{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В этом файлике изучение onnx-файлов, в дальнейшем планируется адаптировать библиотеку для работы с ними",
   "id": "165995cf0f994663"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Auxiliary\n",
    "\n",
    "Всякие вспомогательные функции, взятые из [основного репозитория nanodet](https://github.com/RangiLyu/nanodet?ysclid=mcxcw43rre725659323)\n",
    "\n",
    "Вроде как, к этой модельке не применимые блинб"
   ],
   "id": "486e59b5faa02209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T10:52:50.004822Z",
     "start_time": "2025-07-10T10:52:49.907057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "_COLORS = (\n",
    "    np.array(\n",
    "        [\n",
    "            0.000,\n",
    "            0.447,\n",
    "            0.741,\n",
    "            0.850,\n",
    "            0.325,\n",
    "            0.098,\n",
    "            0.929,\n",
    "            0.694,\n",
    "            0.125,\n",
    "            0.494,\n",
    "            0.184,\n",
    "            0.556,\n",
    "            0.466,\n",
    "            0.674,\n",
    "            0.188,\n",
    "            0.301,\n",
    "            0.745,\n",
    "            0.933,\n",
    "            0.635,\n",
    "            0.078,\n",
    "            0.184,\n",
    "            0.300,\n",
    "            0.300,\n",
    "            0.300,\n",
    "            0.600,\n",
    "            0.600,\n",
    "            0.600,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            0.749,\n",
    "            0.749,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            0.333,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.333,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.500,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            0.500,\n",
    "            0.333,\n",
    "            0.333,\n",
    "            0.500,\n",
    "            0.333,\n",
    "            0.667,\n",
    "            0.500,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            0.500,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            0.500,\n",
    "            0.667,\n",
    "            0.333,\n",
    "            0.500,\n",
    "            0.667,\n",
    "            0.667,\n",
    "            0.500,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            0.500,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.500,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.500,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            0.500,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            1.000,\n",
    "            1.000,\n",
    "            0.667,\n",
    "            1.000,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.833,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.167,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.833,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.167,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.333,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.500,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.667,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.833,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            1.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.000,\n",
    "            0.143,\n",
    "            0.143,\n",
    "            0.143,\n",
    "            0.286,\n",
    "            0.286,\n",
    "            0.286,\n",
    "            0.429,\n",
    "            0.429,\n",
    "            0.429,\n",
    "            0.571,\n",
    "            0.571,\n",
    "            0.571,\n",
    "            0.714,\n",
    "            0.714,\n",
    "            0.714,\n",
    "            0.857,\n",
    "            0.857,\n",
    "            0.857,\n",
    "            0.000,\n",
    "            0.447,\n",
    "            0.741,\n",
    "            0.314,\n",
    "            0.717,\n",
    "            0.741,\n",
    "            0.50,\n",
    "            0.5,\n",
    "            0,\n",
    "        ]\n",
    "    )\n",
    "    .astype(np.float32)\n",
    "    .reshape(-1, 3)\n",
    ")\n",
    "\n",
    "def overlay_bbox_cv(img, dets, class_names, score_thresh):\n",
    "    all_box = []\n",
    "    for label in dets:\n",
    "        for bbox in dets[label]:\n",
    "            score = bbox[-1]\n",
    "            if score > score_thresh:\n",
    "                x0, y0, x1, y1 = [int(i) for i in bbox[:4]]\n",
    "                all_box.append([label, x0, y0, x1, y1, score])\n",
    "    all_box.sort(key=lambda v: v[5])\n",
    "    for box in all_box:\n",
    "        label, x0, y0, x1, y1, score = box\n",
    "        # color = self.cmap(i)[:3]\n",
    "        color = (_COLORS[label] * 255).astype(np.uint8).tolist()\n",
    "        text = \"{}:{:.1f}%\".format(class_names[label], score * 100)\n",
    "        txt_color = (0, 0, 0) if np.mean(_COLORS[label]) > 0.5 else (255, 255, 255)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        txt_size = cv2.getTextSize(text, font, 0.5, 2)[0]\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (x0, y0 - txt_size[1] - 1),\n",
    "            (x0 + txt_size[0] + txt_size[1], y0 - 1),\n",
    "            color,\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(img, text, (x0, y0 - 1), font, 0.5, txt_color, thickness=1)\n",
    "    return img\n",
    "\n",
    "def cv2_imshow(a, convert_bgr_to_rgb=True):\n",
    "    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n",
    "    Args:\n",
    "        a: np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
    "            (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n",
    "            image.\n",
    "        convert_bgr_to_rgb: switch to convert BGR to RGB channel.\n",
    "    \"\"\"\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    # cv2 stores colors as BGR; convert to RGB\n",
    "    if convert_bgr_to_rgb and a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    display(Image.fromarray(a))\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "        'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "        'teddy bear', 'hair drier', 'toothbrush']"
   ],
   "id": "d9156af1f49eb4d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Тесты",
   "id": "de0d3a7e1d8b869b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Информация о модели",
   "id": "aa9e44d65a92744a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-10T12:33:50.139416Z",
     "start_time": "2025-07-10T12:33:50.111872Z"
    }
   },
   "source": [
    "import onnx\n",
    "\n",
    "model_path = 'nanodet_plus_62_192.onnx'\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "onnx.checker.check_model(model)  # Проверяем модель на корректность\n",
    "print(f\"Model has {len(model.graph.input)} inputs and {len(model.graph.output)} outputs.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1 inputs and 1 outputs.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:33:52.209216Z",
     "start_time": "2025-07-10T12:33:52.205104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for input_tensor in model.graph.input:\n",
    "    print(f\"Input name: {input_tensor.name}\")\n",
    "    print(f\"Input shape: {input_tensor.type.tensor_type.shape}\")\n",
    "    print(f\"Input data type: {input_tensor.type.tensor_type.elem_type}\")"
   ],
   "id": "f149a9e7d2d83958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name: data\n",
      "Input shape: dim {\n",
      "  dim_value: 1\n",
      "}\n",
      "dim {\n",
      "  dim_value: 3\n",
      "}\n",
      "dim {\n",
      "  dim_value: 416\n",
      "}\n",
      "dim {\n",
      "  dim_value: 416\n",
      "}\n",
      "\n",
      "Input data type: 1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:33:54.848073Z",
     "start_time": "2025-07-10T12:33:54.843707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for output_tensor in model.graph.output:\n",
    "    print(f\"Output name: {output_tensor.name}\")\n",
    "    print(f\"Output shape: {output_tensor.type.tensor_type.shape}\")\n",
    "    print(f\"Output data type: {output_tensor.type.tensor_type.elem_type}\")"
   ],
   "id": "635aa10906a7c86a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output name: output\n",
      "Output shape: dim {\n",
      "  dim_value: 1\n",
      "}\n",
      "dim {\n",
      "  dim_value: 3598\n",
      "}\n",
      "dim {\n",
      "  dim_value: 94\n",
      "}\n",
      "\n",
      "Output data type: 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Первичные выводы\n",
    "\n",
    "Модель принимает всё вполне логично - изображение в формате (3, 416, 416)\n",
    "\n",
    "А вот выдаёт что-то непонятное - (1, 3598, 94). Быть может, это изображение M*N, и для каждого пикселя вероятность принадлежности к одному из 94 классов? Посмотрим, какие могут быть M и N."
   ],
   "id": "ee04374f6fb2ae43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:38:24.996954Z",
     "start_time": "2025-07-10T12:38:24.991449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import reduce\n",
    "\n",
    "def factors(n):\n",
    "    return set(reduce(\n",
    "        list.__add__,\n",
    "        ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))\n",
    "\n",
    "display(factors(3598))"
   ],
   "id": "2f86b50fd1e72e85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 7, 14, 257, 514, 1799, 3598}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Едва ли, поскольку тогда изображение бы было 7x514 или 14x257\n",
    "\n",
    "Это могло бы быть 3598 найденных объектов, хотя странно, что количество объектов фиксированное, да и что значат 94 признака в таком случае так же неясно. Ведь модель должна быть детектором, то есть возвращать координаты углов и степень уверенности, как это делает изначальный nanodet.\n",
    "\n",
    "Кстати об изначальном [nanodet](https://github.com/RangiLyu/nanodet?ysclid=mcxcw43rre725659323), вот как он работает:\n",
    "- возвращает словарь.\n",
    "- на первом уровне там изображения\n",
    "- для каждого изображения есть словарь с ключами 0..79, ключ - номер класса.\n",
    "- внутри содержатся массивы из 5 элементов - координаты четырех углов и уверенность\n",
    "\n",
    "То есть shape результата оригинального nanodet для одного изображения бы был (1, 79, x, 5), где x - количество найденных объектов для i-го класса"
   ],
   "id": "1089cb02f6dcc842"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Исследование конкретных предсказаний модели\n",
    "\n",
    "Посмотрим, как выглядят предсказания модели для конкретного объекта"
   ],
   "id": "4191c9485fcc3128"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:52:00.545015Z",
     "start_time": "2025-07-10T12:52:00.480268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "\n",
    "model_path = 'nanodet_plus_62_192.onnx'\n",
    "session = ort.InferenceSession(model_path)\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "\n",
    "img = cv2.imread('testimg.jpg').astype(np.float32) / 255.0\n",
    "img = cv2.resize(img, (input_shape[2],input_shape[3])).transpose((2, 0, 1))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "pred = session.run(None, {input_name: img})\n",
    "pred[0].shape # (1, 3598, 94)"
   ],
   "id": "be4feaa9b717dbeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3598, 94)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:52:05.282742Z",
     "start_time": "2025-07-10T12:52:05.276741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = pred[0]\n",
    "prediction[0][0]"
   ],
   "id": "b0d567b3e3ef27e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.162573  , -7.633009  , -6.9549394 , -6.7796087 , -6.8664594 ,\n",
       "       -6.9555717 , -7.705238  , -7.0522127 , -6.64586   , -6.885081  ,\n",
       "       -6.9224095 , -7.4138317 , -6.6935625 , -7.042231  , -6.4374423 ,\n",
       "       -7.481862  , -7.052189  , -7.132023  , -7.0860085 , -6.313938  ,\n",
       "       -7.280868  , -6.3987503 , -6.5284295 , -6.595943  , -6.519201  ,\n",
       "       -6.785137  , -7.203917  , -7.0519457 , -6.8831525 , -7.0770893 ,\n",
       "       -6.6204333 , -6.863559  , -7.1004205 , -6.3609414 , -6.724513  ,\n",
       "       -7.042854  , -7.500639  , -7.2029953 , -6.731427  , -6.8650293 ,\n",
       "       -6.2754393 , -6.21283   , -7.2643843 , -6.584785  , -7.3847322 ,\n",
       "       -7.1197557 , -7.7141156 , -6.334044  , -6.488992  , -7.050642  ,\n",
       "       -6.973954  , -6.98145   , -6.568897  , -8.401864  , -6.8272295 ,\n",
       "       -7.382326  , -6.8288865 , -6.854281  , -6.7770104 , -6.7170777 ,\n",
       "       -6.244225  , -7.230572  ,  0.37940204, -0.75468206, -0.49067935,\n",
       "       -0.69336957, -0.7335961 , -0.7304902 , -0.39784607,  1.9974415 ,\n",
       "        0.08147158, -1.2256051 , -1.3394679 , -1.0859884 , -0.75810957,\n",
       "       -0.59642947, -0.5837649 ,  1.0175414 ,  0.12778881, -0.6800684 ,\n",
       "       -0.8352215 , -0.80288815, -0.18808398, -0.13975692, -0.47429687,\n",
       "        1.4673808 , -1.0124227 , -0.9980619 , -1.1719061 , -1.2645808 ,\n",
       "       -1.1652666 , -0.98762894, -0.1158369 ,  2.4940338 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:17:57.837599Z",
     "start_time": "2025-07-10T12:17:57.832598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = prediction[0][0]\n",
    "print(\"Среднее значение:\", np.mean(data))\n",
    "print(\"Дисперсия:\", np.var(data))\n",
    "print(\"Минимальное значение:\", np.min(data))\n",
    "print(\"Максимальное значение:\", np.max(data))"
   ],
   "id": "db16f615b9fa0b07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение: -4.6960826\n",
      "Дисперсия: 10.080989\n",
      "Минимальное значение: -8.401864\n",
      "Максимальное значение: 2.4940338\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Что-то странное и на вероятности не похоже, если только они зачем-то не были нормализованы в [-10; 10] или какой-то похожий отрезок\n",
    "\n",
    "Наконец, попробуем зарендерить изображение как будто оно действительно содержит координаты углов и уверенности в первых 5 значениях. Особо на успех не надеемся, но мало ли"
   ],
   "id": "827d00ec2e39d26a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T12:54:29.423123Z",
     "start_time": "2025-07-10T12:54:29.386579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Загрузка и предобработка изображения\n",
    "img = cv2.imread('testimg.jpg').astype(np.float32) / 255.0\n",
    "input_height = input_shape[2]  # высота входного изображения\n",
    "input_width = input_shape[3]   # ширина входного изображения\n",
    "resized_img = cv2.resize(img, (input_width, input_height))  # сохраняем для визуализации\n",
    "img = resized_img.transpose((2, 0, 1))  # (channels, height, width)\n",
    "img = np.expand_dims(img, axis=0)       # (1, channels, height, width)\n",
    "\n",
    "# Получение предсказаний\n",
    "pred = session.run(None, {input_name: img})[0]  # (1, 3598, 94)\n",
    "\n",
    "# Обработка предсказаний\n",
    "threshold = 0  # порог уверенности\n",
    "pred = pred[0]   # (3598, 94)\n",
    "\n",
    "for i in range(pred.shape[0]):\n",
    "    objectness = pred[i, 4]  # уверенность в наличии объекта\n",
    "    if objectness > threshold:\n",
    "        # Извлечение координат bounding box (нормализованные)\n",
    "        bbox = pred[i, 0:4]  # [center_x, center_y, width, height]\n",
    "        class_probs = pred[i, 5:]  # вероятности классов\n",
    "        class_id = np.argmax(class_probs)  # индекс класса с максимальной вероятностью\n",
    "        score = objectness * class_probs[class_id]  # итоговый скор\n",
    "\n",
    "        # Преобразование в пиксельные координаты\n",
    "        center_x = bbox[0] * input_width\n",
    "        center_y = bbox[1] * input_height\n",
    "        w = bbox[2] * input_width\n",
    "        h = bbox[3] * input_height\n",
    "        x_left = int(center_x - w / 2)\n",
    "        y_top = int(center_y - h / 2)\n",
    "        x_right = int(center_x + w / 2)\n",
    "        y_bottom = int(center_y + h / 2)\n",
    "\n",
    "        # Отрисовка прямоугольника\n",
    "        cv2.rectangle(resized_img, (x_left, y_top), (x_right, y_bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Добавление подписи\n",
    "        label = f\"Class: {class_id}, Score: {score:.2f}\"\n",
    "        cv2.putText(resized_img, label, (x_left, y_top - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "# Сохранение результата\n",
    "#Image.fromarray(resized_img).show()\n",
    "#cv2.imwrite('output_with_predictions.jpg', resized_img)\n",
    "cv2.imwrite('output_with_predictions.jpg', resized_img*255)"
   ],
   "id": "c2a03184c70ad5a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Да, там действительно содержится что-то другое",
   "id": "fe47292ec4e452d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
